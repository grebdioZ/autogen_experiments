{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842d4017",
   "metadata": {},
   "source": [
    "# Basic Multi-Agent Example with AutoGen\n",
    "\n",
    "This notebook implements a simple multi-agent system using AutoGen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8054ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "import timeit\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utilities import (\n",
    "    create_chat_completion_client,    \n",
    "    adjust_properties_for_fixed_response,    \n",
    "    load_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b6c1917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4.1-nano type: openai\n"
     ]
    }
   ],
   "source": [
    "model = load_model_config()\n",
    "# model = load_model_config(model_name=\"gpt-oss:20b\")\n",
    "# model = load_model_config(model_name=\"qwen3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375bd1f",
   "metadata": {},
   "source": [
    "Set the joke's topic\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1be891ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Animals\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2fdaa3",
   "metadata": {},
   "source": [
    "Select Model and Agent Configuration\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce96c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentConfig = {\n",
    "    \"Author\": dict(\n",
    "        system_message=\"Write a SHORT joke above the provided topic.\"\n",
    "    ),\n",
    "    \"SmartassEditor\": dict(\n",
    "        system_message=\"Analyze the joke, explain why it is funny or not funny, and make it funnier without making it longer.\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# For testing, we can fix an agent's response to a known answer\n",
    "#adjust_properties_for_fixed_response(agentConfig[\"Author\"], \"What do you call a magic dog? A Labracadabrador.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e278d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create model client\n",
    "model_client = create_chat_completion_client(model)\n",
    "\n",
    "agents = []  # start with a user proxy for the researcher\n",
    "\n",
    "for agent_type, props in agentConfig.items():\n",
    "    agents.append(\n",
    "        AssistantAgent(\n",
    "            name=agent_type,\n",
    "            **props,  # type: ignore\n",
    "            model_client=model_client,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf867c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up termination conditions\n",
    "termination = MaxMessageTermination(max_messages=10) #len(agents))\n",
    "\n",
    "# Create the team\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=agents,\n",
    "    termination_condition=termination,\n",
    "    max_turns=len(agents) # we don't really want it to go round\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92697f14",
   "metadata": {},
   "source": [
    "Start the System\n",
    "==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6085732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Generation result (took 1.23 sec.) resulted in 3 messages.\n"
     ]
    }
   ],
   "source": [
    "async def invent_joke(topic: str):\n",
    "    start_time_s = timeit.default_timer()\n",
    "    result = await team.run(task=f\"Invent a short joke about: {topic}\")\n",
    "    elapsed = timeit.default_timer()-start_time_s\n",
    "    print(f\"üîç Generation result (took {elapsed:.2f} sec.) resulted in {len(result.messages)} messages.\")\n",
    "    return result  # Return the result for further exploration\n",
    "\n",
    "# Run the deep dive\n",
    "result = await invent_joke(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53d535",
   "metadata": {},
   "source": [
    "Explore Results\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14cca613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop reason: Maximum number of turns 2 reached.\n",
      "Message Sequence:\n",
      " - user: Invent a short joke about: Animals\n",
      " - Author: Why did the scarecrow become friends with the cow? Because he knew how to moo-ve people!\n",
      " - SmartassEditor: This joke is funny because it plays on the word ‚Äúmoo,‚Äù which is the sound cows make, combining it with ‚Äúmove‚Äù to create a pun. The humor comes from the unexpected link between a scarecrow, a farm figure, and a cow, highlighting the playful wordplay.\n",
      "\n",
      "To make it funnier without making it longer:\n",
      "**\"Why did the scarecrow become friends with the cow? Because he was outstanding in his field‚Äîand knew how to moo-ve!\"**\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.messages import BaseTextChatMessage\n",
    "\n",
    "print(\"Stop reason:\", result.stop_reason)\n",
    "assert isinstance(result.messages[-1], BaseTextChatMessage)\n",
    "\n",
    "print(\"Message Sequence:\")\n",
    "for m in result.messages:\n",
    "    assert isinstance(m, BaseTextChatMessage), f\"Unexpected message type: {type(m)}\"\n",
    "    message = m.content\n",
    "    print(f\" - {m.source}: {message}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
