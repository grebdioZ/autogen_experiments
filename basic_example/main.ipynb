{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842d4017",
   "metadata": {},
   "source": [
    "# Basic Multi-Agent Example with AutoGen\n",
    "\n",
    "This notebook implements a simple multi-agent system using AutoGen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8054ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "import timeit\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_agentchat.tools import TeamTool\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.curdir, \"..\")))\n",
    "\n",
    "from tools import (\n",
    "    create_chat_completion_client,\n",
    "    current_datetime_utc_tool,\n",
    "    adjust_properties_for_fixed_response,\n",
    "    get_tavily_search_tool,\n",
    "    get_attributes,\n",
    "    load_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c88307",
   "metadata": {},
   "source": [
    "#### Note: You need a tavily API key to use the web search tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b6c1917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-4.1-nano type: openai\n"
     ]
    }
   ],
   "source": [
    "model = load_model_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375bd1f",
   "metadata": {},
   "source": [
    "Set the joke's topic\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1be891ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Animals\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2fdaa3",
   "metadata": {},
   "source": [
    "Select Model and Agent Configuration\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cce96c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentConfig = {\n",
    "    \"Author\": dict(\n",
    "        system_message=\"Write a SHORT joke above the provided topic.\"\n",
    "    ),\n",
    "    \"SmartassEditor\": dict(\n",
    "        system_message=\"Analyze the joke, explain why it is funny or not funny, and make it funnier without making it longer.\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# For testing, we can fix an agent's response to a known answer\n",
    "#adjust_properties_for_fixed_response(agentConfig[\"Author\"], \"What do you call a magic dog? A Labracadabrador.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1e278d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create model client\n",
    "model_client = create_chat_completion_client(model)\n",
    "\n",
    "agents = []  # start with a user proxy for the researcher\n",
    "\n",
    "for agent_type, props in agentConfig.items():\n",
    "    agents.append(\n",
    "        AssistantAgent(\n",
    "            name=agent_type,\n",
    "            **props,\n",
    "            model_client=model_client,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcf867c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up termination conditions\n",
    "termination = MaxMessageTermination(max_messages=10) #len(agents))\n",
    "\n",
    "# Create the team\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=agents,\n",
    "    termination_condition=termination,\n",
    "    max_turns=len(agents) # we don't really want it to go round\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92697f14",
   "metadata": {},
   "source": [
    "Start the System\n",
    "==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6085732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Generation result (took 1.14 sec.) resulted in 3 messages.\n"
     ]
    }
   ],
   "source": [
    "async def invent_joke(topic: str):\n",
    "    start_time_s = timeit.default_timer()\n",
    "    result = await team.run(task=f\"Invent a short joke about: {topic}\")\n",
    "    elapsed = timeit.default_timer()-start_time_s\n",
    "    print(f\"üîç Generation result (took {elapsed:.2f} sec.) resulted in {len(result.messages)} messages.\")\n",
    "    return result  # Return the result for further exploration\n",
    "\n",
    "# Run the deep dive\n",
    "result = await invent_joke(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53d535",
   "metadata": {},
   "source": [
    "Explore Results\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3254dbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result type: <class 'autogen_agentchat.base._task.TaskResult'>\n",
      "Message Sequence:\n",
      "\n",
      "----------------------------------------------------------------\n",
      "MESSAGE 0 [user]:\n",
      "Invent a short joke about: Animals\n",
      "\n",
      "----------------------------------------------------------------\n",
      "MESSAGE 1 [Author]:\n",
      "Why did the squirrel bring a ladder to the tree?  \n",
      "Because it wanted to get to the nutty level!\n",
      "\n",
      "----------------------------------------------------------------\n",
      "MESSAGE 2 [SmartassEditor]:\n",
      "The joke is funny because it plays on the double meaning of \"nutty,\" referring both to the squirrel‚Äôs love for nuts and a humorous \"higher level\" ‚Äî like climbing a ladder to reach the next \"stage\" of nuttiness. It‚Äôs a clever pun that combines animal behavior with a common phrase.\n",
      "\n",
      "To make it funnier without adding length:  \n",
      "\"Why did the squirrel bring a ladder? To reach the top nut-venture!\"\n"
     ]
    }
   ],
   "source": [
    "# Display the full result structure\n",
    "print(\"Result type:\", type(result))\n",
    "\n",
    "# print(\"\\nResult attributes:\")\n",
    "# print(get_attributes(result))\n",
    "# print(\"\\nMessage attributes:\")\n",
    "# print(get_attributes(result.messages[-1]))\n",
    "\n",
    "print(\"Message Sequence:\")\n",
    "for i, m in enumerate(result.messages):\n",
    "    print(f\"\\n----------------------------------------------------------------\")\n",
    "    print(f\"MESSAGE {i} [{m.source}]:\\n{m.content}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35292aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "await model_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14cca613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop reason: Maximum number of turns 2 reached.\n",
      "Message Sequence:\n",
      " - user: Invent a short joke about: Animals\n",
      " - Author: Why did the squirrel bring a ladder to the tree?  \n",
      "Because it wanted to get to the nutty level!\n",
      " - SmartassEditor: The joke is funny because it plays on the double meaning of \"nutty,\" referring both to the squirrel‚Äôs love for nuts and a humorous \"higher level\" ‚Äî like climbing a ladder to reach the next \"stage\" of nuttiness. It‚Äôs a clever pun that combines animal behavior with a common phrase.\n",
      "\n",
      "To make it funnier without adding length:  \n",
      "\"Why did the squirrel bring a ladder? To reach the top nut-venture!\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from autogen_agentchat.messages import BaseTextChatMessage\n",
    "\n",
    "print(\"Stop reason:\", result.stop_reason)\n",
    "assert isinstance(result.messages[-1], BaseTextChatMessage)\n",
    "\n",
    "print(\"Message Sequence:\")\n",
    "for m in result.messages:\n",
    "    assert isinstance(m, BaseTextChatMessage), f\"Unexpected message type: {type(m)}\"\n",
    "    message = m.content\n",
    "    print(f\" - {m.source}: {message}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
